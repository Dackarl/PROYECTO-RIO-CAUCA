INICIO: Preparaci√≥n del Entorno y Carga de Datos

  //--- Parte 1: Cargar y verificar las configuraciones ---

  // Se importa un m√≥dulo personalizado que contiene definiciones y reglas.
  // Es como abrir tu libro de apuntes antes de empezar a trabajar.
  IMPORTAR el m√≥dulo 'diccionario'.
  ASEGURARSE de cargar la versi√≥n m√°s reciente del m√≥dulo 'diccionario' (para evitar usar una versi√≥n antigua en cach√©).

  // Se realizan varias comprobaciones para asegurar que todo est√° en orden.
  VERIFICAR que el m√≥dulo 'diccionario' se carg√≥ correctamente:
    - CONFIRMAR que la lista de 'diccionario_variables' existe dentro del m√≥dulo.
    - INSPECCIONAR los contenidos del m√≥dulo para ver qu√© elementos est√°n disponibles.
    - COMPARAR el n√∫mero de 'variables' con el n√∫mero de 'reglas' para asegurar que coinciden (en este caso, hay 53 de cada uno).

  //--- Parte 2: Cargar el conjunto de datos principal ---

  // Ahora, se carga el archivo con los datos de calidad del agua.
  LEER el archivo 'Calidad_del_agua_del_Rio_Cauca.csv'.
    - ESPECIFICAR que el separador de columnas es un punto y coma ';'.
  GUARDAR toda la informaci√≥n en una tabla principal llamada 'df'.

  // Se echa un primer vistazo a los datos.
  MOSTRAR las primeras 5 filas de la tabla 'df' para confirmar que se carg√≥ correctamente.

FIN: Preparaci√≥n y Carga de Datos

// A partir de la tabla de datos original ('df'), se crea una nueva versi√≥n.
  CREAR una nueva tabla llamada 'df_sin_columnas'.
  ELIMINAR de esta nueva tabla las columnas 'FECHA DE MUESTREO' y 'ESTACIONES',
  porque no son necesarias para el an√°lisis posterior.

  //--- Parte 3: Carga y Procesamiento del Diccionario de Variables ---
  
  // Se define un proceso inteligente para leer un archivo Excel que funciona
  // como una base de conocimiento o "diccionario" de todas las variables.
  DEFINIR la funci√≥n 'cargar_diccionario':
    1. ABRIR el archivo Excel 'diccionario.xlsx'.
    2. IDENTIFICAR autom√°ticamente las columnas importantes (par√°metro, definici√≥n, rangos de color, etc.) sin importar su orden en el archivo.
    3. RECORRER el archivo fila por fila.
    4. PARA CADA fila (que representa un par√°metro de calidad del agua):
        a. EXTRAER su nombre, definici√≥n, y otra informaci√≥n descriptiva.
        b. INTERPRETAR los textos que definen los rangos de calidad (ej. '10 - 20', '>50', '‚â§ 5').
        c. ALMACENAR toda esta informaci√≥n de forma organizada en dos memorias: una para las descripciones ('diccionario_variables') y otra para las reglas de colores ('reglas_por_parametro').

  // Se ejecuta la funci√≥n anterior para cargar toda la base de conocimiento en el programa.
  EJECUTAR 'cargar_diccionario' y guardar los resultados.

  //--- Parte 4: Creaci√≥n de la Interfaz de Usuario Interactiva ---

  // Se crean los componentes visuales de la herramienta.
  CREAR una caja de texto para que el usuario pueda **buscar** un par√°metro.
  CREAR un men√∫ desplegable para **seleccionar** un par√°metro de la lista cargada del Excel.
  CREAR espacios de texto vac√≠os para **mostrar** la informaci√≥n detallada:
    - Definici√≥n
    - Relaci√≥n con la contaminaci√≥n
    - Referencia
    - Rangos por color

  // Se programa el comportamiento interactivo de la herramienta.
  PROGRAMAR la l√≥gica para que, **CUANDO el usuario seleccione un par√°metro** del men√∫ desplegable:
    1. BUSCAR toda la informaci√≥n de ese par√°metro en la memoria.
    2. MOSTRAR la definici√≥n, relaci√≥n y referencia en sus espacios correspondientes.
    3. FORMATEAR y MOSTRAR los rangos de calidad con sus colores y emojis (ej. üü¢ Verde, üü° Amarillo, üü† Naranja, üî¥ Rojo).

  PROGRAMAR la l√≥gica para que, **CUANDO el usuario escriba algo** en la caja de b√∫squeda:
    1. FILTRAR las opciones del men√∫ desplegable para que solo muestren las que coinciden con la b√∫squeda.

  // Finalmente, se ensambla y muestra la herramienta.
  ORGANIZAR todos estos elementos visuales en una sola interfaz vertical.
  MOSTRAR la interfaz interactiva completa al usuario.

FIN: Limpieza y Creaci√≥n del Explorador

INICIO: An√°lisis, Limpieza y Filtrado de Datos

  //--- Parte 5: Limpieza Profunda y Estandarizaci√≥n de Tipos de Datos ---

  // Se crea una copia de la tabla para trabajar de forma segura sin alterar el original.
  CREAR una nueva tabla 'df_eda' como una copia de 'df_sin_columnas'.

  // Se realiza una limpieza exhaustiva para asegurar que todos los datos sean num√©ricos.
  RECORRER cada columna de la tabla 'df_eda':
    1. CONVERTIR todos los valores de la columna a texto.
    2. REEMPLAZAR las comas (',') por puntos ('.') para estandarizar el formato de los decimales.
    3. INTENTAR convertir el texto resultante a un valor num√©rico.
    4. Si un valor no se puede convertir (porque es un texto como 'N/A'), marcarlo como 'dato faltante'.

  // Se eliminan las columnas que puedan haber quedado completamente vac√≠as tras la limpieza.
  ELIMINAR cualquier columna que contenga √öNICAMENTE datos faltantes.

  // Se verifica el resultado.
  MOSTRAR un resumen de la tabla 'df_eda' para confirmar que todas las columnas son de tipo num√©rico.

  //--- Parte 6: C√°lculo de Estad√≠sticas Descriptivas Completas ---

  // Se calcula un perfil estad√≠stico detallado para cada variable.
  PARA CADA columna en la tabla 'df_eda', CALCULAR un conjunto completo de estad√≠sticas. Esto incluye:
    - Medidas b√°sicas: media, mediana, desviaci√≥n est√°ndar, m√≠nimo y m√°ximo.
    - Medidas de distribuci√≥n: Rango Intercuart√≠lico (IQR), asimetr√≠a (Skewness) y curtosis.
    - Medidas de calidad: Porcentaje de datos v√°lidos (no faltantes).
    - Y otras medidas avanzadas como el Coeficiente de Variaci√≥n (CV).

  // Se mejora la presentaci√≥n de la tabla de estad√≠sticas para que sea m√°s legible.
  RENOMBRAR algunas columnas para que sean m√°s claras (ej. '50%' se convierte en 'Mediana').
  ORGANIZAR las columnas de la tabla de estad√≠sticas en un orden l√≥gico y predefinido.
  APLICAR un formato visual a los n√∫meros (ej. redondear a 2 decimales) para que la tabla final sea limpia y profesional.
  
  // Se muestra el resultado final del an√°lisis.
  MOSTRAR la tabla de estad√≠sticas completa y formateada.

  //--- Parte 7: Filtrado de Variables por Calidad de Datos ---

  // Se toma una decisi√≥n basada en la cantidad de datos faltantes.
  ESTABLECER un 'umbral de calidad' del 80%.
  (Esto significa que solo confiaremos en las variables que tengan al menos el 80% de sus datos completos).

  // Se identifican las variables que no pasan el filtro.
  IDENTIFICAR y mostrar una lista de las variables que tienen MENOS del 80% de datos v√°lidos.

  // Se crea el conjunto de datos final y limpio.
  SELECCIONAR la lista de todas las variables que S√ç cumplen o superan el umbral del 80%.
  CREAR una nueva tabla final, 'df_filtrado', que contenga √öNICAMENTE estas columnas de alta calidad.
  
  // Se informa el resultado del filtrado.
  MOSTRAR un mensaje indicando cu√°ntas variables fueron mantenidas (ej. 27 de 39) y mostrar sus nombres.

FIN: An√°lisis y Filtrado Completados

INICIO: Selecci√≥n de Variables Objetivo y Preparaci√≥n de Datos Finales

  //--- Parte 8: Estandarizaci√≥n de Nombres de Variables ---

  // Se crea una funci√≥n para simplificar y limpiar los nombres de las columnas.
  DEFINIR un proceso de 'limpieza de texto' para nombres de columnas que hace lo siguiente:
    1. Convierte todo a min√∫sculas.
    2. Elimina acentos (ej. 'ox√≠geno' -> 'oxigeno').
    3. Quita s√≠mbolos especiales como (), /, -, _.
    4. Normaliza los espacios para que solo haya uno entre palabras.
  
  // Se aplica esta limpieza a todas las columnas del conjunto de datos filtrado.
  APLICAR el proceso de limpieza a cada nombre de columna en la tabla 'df_filtrado'.
  GUARDAR un mapa que relacione cada nombre original con su versi√≥n simplificada.
  MOSTRAR esta lista para verificar que la limpieza funcion√≥ correctamente.

  //--- Parte 9: Selecci√≥n Interactiva de la(s) Variable(s) Objetivo ---

  // Se construye una interfaz para que el usuario elija qu√© variable(s) quiere predecir.
  CREAR una interfaz de usuario interactiva:
    - PARA CADA variable disponible, MOSTRAR una caja de selecci√≥n (checkbox) con su nombre.
      - A√±adir una marca (‚úÖ o ‚ùå) para indicar si la variable tiene informaci√≥n de contexto en el 'diccionario' cargado previamente.
    - CREAR un bot√≥n de 'Confirmar selecci√≥n'.

  // Se programa el comportamiento de la interfaz.
  PROGRAMAR la l√≥gica para que, CUANDO el usuario presione el bot√≥n 'Confirmar':
    1. VERIFICAR que se hayan seleccionado 1 o 2 variables (ni m√°s, ni menos).
    2. Si la selecci√≥n es v√°lida, GUARDAR los nombres de las variables elegidas en una memoria global llamada 'objetivos'.
    3. MOSTRAR un mensaje de confirmaci√≥n con las variables que se seleccionaron.

  // Se muestra la herramienta al usuario.
  MOSTRAR esta interfaz de checkboxes y el bot√≥n.

  //--- Parte 10: Preparaci√≥n Final de Datos para Modelado (Creaci√≥n de X y y) ---

  // Se define el proceso final para dejar los datos listos para un modelo de Machine Learning.
  DEFINIR un proceso automatizado ('get_X_y_para') que, dado un 'objetivo', hace lo siguiente:
    1. **Separar Objetivo (y):** Tomar la columna 'objetivo' y guardarla como el vector 'y'. Se eliminan de 'y' las filas que tengan datos faltantes.
    2. **Separar Predictoras (X):** Crear la tabla 'X' con todas las dem√°s columnas que no son el objetivo.
    3. **Alinear Datos:** Asegurarse de que la tabla 'X' contenga exactamente las mismas filas que el vector 'y'.
    4. **Limpiar Predictoras (X):** Realizar una limpieza final en 'X':
        a. Quitar cualquier columna que no sea num√©rica.
        b. Eliminar columnas que sean constantes (tienen el mismo valor en todas las filas), ya que no aportan informaci√≥n.
    5. **Verificaci√≥n Final:** Realizar una √∫ltima alineaci√≥n para garantizar que 'X' y 'y' son perfectamente compatibles.
    6. **Devolver** los conjuntos de datos 'X' (predictores) y 'y' (objetivo) listos para el modelo.

  // Se ejecuta el proceso anterior con las variables que el usuario seleccion√≥.
  VERIFICAR si el usuario ya seleccion√≥ sus 'objetivos' con la interfaz interactiva.
  SI lo hizo, ENTONCES PARA CADA 'objetivo' seleccionado:
    - EJECUTAR el proceso de preparaci√≥n para obtener su 'X' y 'y' correspondientes.
    - MOSTRAR el tama√±o (n√∫mero de filas y columnas) de los conjuntos 'X' y 'y' resultantes.

FIN: Datos Preparados y Listos para Modelar

INICIO: Tratamiento de Datos Faltantes y An√°lisis de Outliers

  //--- Parte 11: Tratamiento de Datos Faltantes (Imputaci√≥n KNN) ---
  
  // 11.1: Diagn√≥stico Inicial
  // Antes de arreglar el problema, primero se mide su magnitud.
  CALCULAR y MOSTRAR una tabla con el conteo y porcentaje de datos faltantes para cada variable.
  GENERAR un 'mapa de calor' visual para identificar patrones en los datos faltantes (d√≥nde el amarillo indica un dato faltante).
  
  // 11.2: Proceso de Imputaci√≥n
  // Se rellenan los huecos de forma inteligente.
  PREPARAR los datos para la imputaci√≥n, escalando todas las variables a un rango est√°ndar.
  APLICAR el algoritmo de imputaci√≥n 'K-Nearest Neighbors' (KNN).
    // Este m√©todo 'adivina' los valores faltantes bas√°ndose en los 5 registros m√°s similares que s√≠ tienen datos.
  REVERTIR el escalado para devolver los datos a su escala original, ahora sin valores faltantes.

  // 11.3: Verificaci√≥n
  // Se comprueba que la operaci√≥n fue exitosa.
  GENERAR un segundo 'mapa de calor' para confirmar visualmente que no quedan datos faltantes (el mapa debe ser de un solo color s√≥lido).

  //--- Parte 12: An√°lisis y Tratamiento de Valores At√≠picos (Outliers) ---

// 12.1: Inspecci√≥n Visual Inicial (Boxplots)
// (Este paso se mantiene como lo describimos antes)
PARA CADA variable en los datos (ya imputados):
  1. APLICAR una transformaci√≥n logar√≠tmica 'segura'.
  2. GENERAR un gr√°fico de 'caja y bigotes' (boxplot) para identificar visualmente la presencia de outliers.

// 12.2: Inspecci√≥n Visual de Distribuciones (Histogramas)
DEFINIR una regla para decidir si una variable necesita una transformaci√≥n logar√≠tmica (basado en su asimetr√≠a o "skewness").
DEFINIR un proceso de 'preparaci√≥n para graficar' que:
  a. Aplica la transformaci√≥n logar√≠tmica solo si la regla anterior lo indica.
  b. 'Winsoriza' los datos para recortar los valores m√°s extremos y facilitar la visualizaci√≥n.

RECORRER todas las variables num√©ricas en p√°ginas (ej. 16 gr√°ficos por p√°gina).
PARA CADA variable:
  1. APLICAR el proceso de 'preparaci√≥n para graficar'.
  2. GENERAR un histograma para visualizar su distribuci√≥n.
MOSTRAR las p√°ginas de gr√°ficos con un t√≠tulo general.

// 12.3: An√°lisis Cuantitativo de Variables Problem√°ticas
SELECCIONAR las variables que parecen m√°s problem√°ticas.
PARA CADA una de estas variables:
  a. MOSTRAR los 10 valores m√°s altos para inspecci√≥n manual.
  b. CALCULAR un informe estad√≠stico con el n√∫mero y porcentaje exacto de outliers (m√©todo IQR).

// 12.4: Demostraci√≥n de Tratamiento en Boxplots
DEFINIR y APLICAR el proceso de transformaci√≥n 'robusta' (log + winsorize) a las variables problem√°ticas.
GENERAR nuevos boxplots para mostrar c√≥mo la t√©cnica reduce los outliers extremos.

FIN: Imputaci√≥n y An√°lisis de Outliers Completado

// 13.1: Preparaci√≥n y An√°lisis de Correlaci√≥n
// Se examina la relaci√≥n entre las variables predictoras.
PREPARAR un conjunto de datos num√©rico que contenga √∫nicamente las variables predictoras (excluyendo las variables objetivo).
CALCULAR las matrices de correlaci√≥n entre todos los predictores, usando los m√©todos de Pearson y Spearman.
GENERAR 'mapas de calor' (heatmaps) para visualizar estas correlaciones, mostrando las relaciones m√°s fuertes.
IDENTIFICAR y MOSTRAR las parejas de predictores que tienen una correlaci√≥n muy fuerte (ej. mayor a 0.8).

// 13.2: Filtro Autom√°tico por Colinealidad (Heur√≠stica)
// Se elimina la redundancia de forma inteligente.
DEFINIR un proceso autom√°tico para eliminar una variable de cada par altamente correlacionado (ej. Spearman > 0.85).
ESTABLECER una regla inteligente para decidir cu√°l variable conservar de cada par:
  - **Opci√≥n A (si hay objetivos definidos):** Se conservar√° el predictor que est√© m√°s fuertemente correlacionado con la variable objetivo.
  - **Opci√≥n B (si no hay objetivos definidos):** Como plan B, se conservar√° el predictor que, en promedio, tenga la correlaci√≥n m√°s baja con el resto de predictores.

APLICAR esta regla a todos los pares conflictivos para crear una lista de variables a eliminar.
CREAR una nueva tabla ('df_corr_filtered') eliminando estas variables redundantes y MOSTRAR cu√°ntas variables se conservaron.

//--- Parte 14: Reducci√≥n de Multicolinealidad con VIF Iterativo ---

// 14.1: Proceso Iterativo de VIF
// Se aplica un m√©todo m√°s avanzado para refinar la selecci√≥n.
APLICAR el m√©todo del 'Factor de Inflaci√≥n de la Varianza' (VIF) para detectar y eliminar la multicolinealidad restante.
INICIAR un proceso repetitivo (bucle) que se ejecuta hasta que no queden variables con VIF alto:
  1. En cada 'iteraci√≥n', CALCULAR el VIF para todas las variables restantes.
  2. IDENTIFICAR la variable con el VIF m√°s alto.
  3. **Condici√≥n de Parada:** Si el VIF m√°s alto ya es aceptable (ej. < 10), DETENER el proceso.
  4. **Regla de Protecci√≥n:** Si la variable con el VIF m√°s alto es una variable objetivo, DETENER el proceso para no eliminarla.
  5. **Eliminaci√≥n:** Si ninguna de las condiciones anteriores se cumple, ELIMINAR la variable con el VIF m√°s alto y volver al paso 1.

MOSTRAR un resumen de las variables eliminadas en cada iteraci√≥n y la lista final de variables conservadas.

// 14.2: An√°lisis Final de Correlaci√≥n (Objetivo vs. Predictores)
// Se verifica la relaci√≥n de los predictores finales con el objetivo.
COMO verificaci√≥n final, PARA CADA variable objetivo:
  CALCULAR y MOSTRAR una lista ordenada de la correlaci√≥n entre el objetivo y cada uno de los predictores finales.

FIN: Selecci√≥n de Caracter√≠sticas Completada

//--- Parte 15: Pipeline Automatizado de Modelado y Evaluaci√≥n ---

// 15.1: Definici√≥n de Herramientas y Modelos
// Se definen los procesos y los 'competidores' del torneo de modelado.
DEFINIR un conjunto de procesos auxiliares para automatizar tareas:
  - **Proceso 'Seleccionar Datos de Entrada':** Decide autom√°ticamente cu√°l es el mejor conjunto de datos de predictores (X) para usar (dando preferencia al que pas√≥ el filtro VIF).
  - **Proceso 'Construir X y y':** Toma un objetivo y prepara los conjuntos de datos finales y alineados para el modelado.
  - **Proceso 'Evaluar Modelo':** Una rutina est√°ndar que entrena un modelo, mide su rendimiento (con R2, RMSE, MAE) y guarda los resultados.

CREAR un 'registro de modelos' con una lista de todos los algoritmos que competir√°n:
  - Incluir modelos como Regresi√≥n Lineal, √Årbol de Decisi√≥n, Random Forest, SVR y una Red Neuronal (MLP).
  - Configurar autom√°ticamente los modelos que necesitan escalado de datos dentro de un 'pipeline'.
  - Incluir opcionalmente el modelo XGBoost si est√° instalado en el sistema.

// 15.2: Proceso Principal de Entrenamiento y Evaluaci√≥n
// El coraz√≥n del pipeline: un bucle que lo hace todo para cada objetivo.
VERIFICAR que el usuario haya seleccionado 1 o 2 variables objetivo previamente.
INICIAR un bucle principal que se ejecutar√° PARA CADA una de las variables objetivo seleccionadas:
  
  1. **Preparar Datos:** Usar el proceso 'Construir X y y' para obtener los datos listos para el objetivo actual.
  2. **Dividir Datos:** Separar los datos en un conjunto de entrenamiento (80%) y uno de prueba (20%).
  3. **Competencia de Modelos:** Iniciar un sub-bucle PARA CADA modelo en el 'registro de modelos':
      a. Entrenar y evaluar el modelo usando el proceso 'Evaluar Modelo'.
      b. Guardar los resultados de rendimiento (R2, RMSE, MAE).
      c. Guardar el modelo ya entrenado para uso futuro.
  4. **Consolidar Resultados:** Crear una tabla de resumen con el rendimiento de todos los modelos para el objetivo actual. Ordenarla por el mejor RMSE (menor error).
  5. **Analizar Importancia de Variables:**
      a. Seleccionar un modelo de referencia (preferiblemente Random Forest o el de mejor rendimiento).
      b. Calcular la 'Importancia por Permutaci√≥n' para entender qu√© variables predictoras fueron las m√°s influyentes para las predicciones de ese modelo.
  6. **Mostrar Resultados:** Imprimir en pantalla la tabla de rendimiento de los modelos y la tabla con las variables m√°s importantes para el objetivo actual.

// 15.3: Resumen Global y Almacenamiento de Artefactos
// Se consolidan y guardan todos los resultados finales.
UNA VEZ que el bucle principal ha terminado (procesado todos los objetivos):
  - UNIR los resultados de todos los objetivos en una √∫nica tabla de 'Resumen Global'.
  - MOSTRAR esta tabla resumen.

CREAR un 'paquete' final llamado 'artefactos' que contenga todos los productos importantes del pipeline:
  - Los resultados detallados por objetivo.
  - El resumen global.
  - Todos los modelos ya entrenados.
  - Las tablas de importancia de variables.

INFORMAR al usuario que estos artefactos est√°n listos en memoria para ser explorados sin necesidad de volver a ejecutar todo el proceso.

FIN: Pipeline de Modelado y Evaluaci√≥n Completado

//--- Parte 16: Optimizaci√≥n de Hiperpar√°metros con B√∫squeda Exhaustiva (GridSearchCV) ---

// 16.1: Definici√≥n de Herramientas y Espacios de B√∫squeda
// Se preparan las herramientas de diagn√≥stico y el "men√∫" de opciones para cada modelo.
DEFINIR procesos auxiliares para el diagn√≥stico:
  - "'Alerta de Sobreajuste'": Una funci√≥n que revisa si el rendimiento en los datos de entrenamiento es excesivamente mejor que en los de prueba, lo cual es una se√±al de alarma. üö®

PARA CADA tipo de modelo (Random Forest, XGBoost, etc.):
  - DEFINIR un "'espacio de b√∫squeda'": una lista de diferentes valores para sus configuraciones m√°s importantes (ej. para un √°rbol: `profundidad m√°xima`, `m√≠nimo de muestras por hoja`, etc.).
  - Seleccionar rangos de b√∫squeda razonables para evitar configuraciones extremas que tiendan al sobreajuste.

// 16.2: Proceso Principal de Optimizaci√≥n
// Se inicia un torneo para encontrar la mejor versi√≥n de cada modelo.
INICIAR un bucle principal que se ejecutar√° PARA CADA una de las variables objetivo.
  1. PREPARAR y dividir los datos en conjuntos de entrenamiento y prueba para el objetivo actual.
  2. INICIAR un sub-bucle PARA CADA modelo y su 'espacio de b√∫squeda' definido:
      a. CONFIGURAR un proceso de 'B√∫squeda en Rejilla' (GridSearchCV).
      b. INSTRUIR al proceso para que pruebe **todas las combinaciones posibles** de los hiperpar√°metros definidos.
      c. USAR validaci√≥n cruzada (CV de 5 pliegues) para evaluar cada combinaci√≥n de forma robusta.
      d. ESPECIFICAR que el objetivo es encontrar la combinaci√≥n que minimice el error (RMSE).
      e. EJECUTAR la b√∫squeda, lo cual puede tomar un tiempo considerable. ‚è≥

// 16.3: Diagn√≥stico y Consolidaci√≥n de Resultados
// Para cada modelo, se analiza al ganador de la b√∫squeda.
UNA VEZ que la b√∫squeda para un modelo termina:
  1. OBTENER el modelo con la mejor combinaci√≥n de hiperpar√°metros encontrada. üèÜ
  2. EVALUAR su rendimiento en los datos de entrenamiento y en los de prueba.
  3. LLAMAR a la 'Alerta de Sobreajuste' para verificar la salud del modelo.
  4. MOSTRAR un informe detallado en pantalla con: la mejor configuraci√≥n, el rendimiento en train/test/CV y las posibles alertas.
  5. GUARDAR el rendimiento del modelo optimizado en una lista de resultados.

// 16.4: Resumen Global de Modelos Optimizados
// Se presenta la tabla final con los campeones de cada categor√≠a.
UNA VEZ que el bucle principal ha procesado todos los modelos para todos los objetivos:
  - UNIR todos los resultados en una √∫nica tabla de 'Resumen Global'.
  - MOSTRAR esta tabla final, ordenada por el mejor rendimiento, para comparar los modelos ya optimizados.

FIN: Optimizaci√≥n de Hiperpar√°metros Completada

//--- Parte 17: Optimizaci√≥n Inteligente de Hiperpar√°metros con Optuna ---

// 17.1: Configuraci√≥n y Definici√≥n de "Estudios"
// Se prepara el entorno para una b√∫squeda guiada e inteligente.
ESTABLECER los par√°metros de la b√∫squeda: n√∫mero de intentos por modelo (`N_TRIALS`), n√∫mero de pliegues para la validaci√≥n cruzada, y una semilla para la reproducibilidad.
DEFINIR una "funci√≥n objetivo" (o 'estudio') PARA CADA tipo de modelo:
  - Cada 'estudio' le describe a Optuna qu√© hiperpar√°metros probar y en qu√© rangos (ej. `profundidad del √°rbol` entre 2 y 20).
  - La misi√≥n del 'estudio' es construir un modelo con los par√°metros sugeridos por Optuna y devolver su rendimiento (error RMSE) medido con validaci√≥n cruzada.

// 17.2: Proceso Principal de Optimizaci√≥n Inteligente
// Se le pide a Optuna que encuentre la mejor configuraci√≥n para cada modelo.
INICIAR un bucle principal que se ejecutar√° PARA CADA una de las variables objetivo.
  1. PREPARAR y dividir los datos en conjuntos de entrenamiento y prueba para el objetivo actual.
  2. INICIAR un sub-bucle PARA CADA 'estudio' de modelo definido:
      a. CREAR un 'estudio' de Optuna con el objetivo de **minimizar** el error.
      b. INICIAR el proceso de optimizaci√≥n (`study.optimize`). Optuna llamar√° a la "funci√≥n objetivo" repetidamente (`N_TRIALS` veces), usando su inteligencia para proponer mejores combinaciones de hiperpar√°metros en cada intento. üöÄ

// 17.3: Evaluaci√≥n Final y Almacenamiento de Resultados
// Se toma la mejor configuraci√≥n encontrada y se eval√∫a en datos nunca antes vistos.
UNA VEZ que Optuna termina la b√∫squeda para un modelo:
  1. OBTENER la mejor combinaci√≥n de hiperpar√°metros encontrada.
  2. RECONSTRUIR el modelo usando esa configuraci√≥n √≥ptima.
  3. ENTRENAR este modelo final con todos los datos de entrenamiento.
  4. EVALUAR su rendimiento definitivo en el conjunto de prueba (datos que nunca vio durante la optimizaci√≥n).
  5. GUARDAR los resultados (rendimiento en CV, en Test y los mejores par√°metros) en una lista.
  6. ALMACENAR el modelo final ya entrenado en memoria.

// 17.4: Resumen Global y Guardado de Artefactos
// Se consolidan los resultados y se guardan los productos finales.
UNA VEZ que el bucle principal ha optimizado todos los modelos para todos los objetivos:
  - UNIR todos los resultados en una √∫nica tabla de 'Resumen Global'.
  - MOSTRAR esta tabla final para comparar los modelos optimizados.
  - SI est√° activado, GUARDAR los artefactos finales en disco para uso futuro:
    - La tabla de resumen (en formato Parquet).
    - Todos los mejores modelos entrenados (en un archivo Pickle).
  - INFORMAR al usuario de la ubicaci√≥n de los archivos guardados. üíæ

FIN: Optimizaci√≥n Inteligente Completada

//--- Parte 18: Sistema de Registro de Corridas (Logger) para Experimentaci√≥n ---

// 18.1: Arquitectura del Logger
// Se establece una "bit√°cora" para guardar los resultados de los experimentos.
// Esta bit√°cora tiene dos modos de operaci√≥n:
// - En Memoria: Un registro r√°pido que vive mientras el programa se ejecuta, ideal para an√°lisis interactivo.
// - Persistente (en Disco): La capacidad opcional de guardar cada experimento en archivos para que los resultados no se pierdan al cerrar el programa.

// 18.2: Proceso de Registro de una Nueva Corrida (`log_run`)
// Se define el proceso principal para registrar un nuevo experimento.
1. **Generar Metadata:** Al registrar una corrida, primero se crea una "etiqueta" con su informaci√≥n clave:
   - Un ID √∫nico basado en la fecha y hora exacta. üïí
   - La lista de variables objetivo.
   - La lista de variables predictoras.
   - Una "firma digital" (hash) √∫nica para el conjunto de predictores, que permite compararlos de forma fiable.

2. **Implementar L√≥gica de Sobrescritura:** Para mantener la bit√°cora limpia en aplicaciones interactivas:
   - Antes de guardar, verificar si ya existe una corrida anterior con la **misma combinaci√≥n exacta** de objetivos y predictores.
   - Si existe, eliminar el registro antiguo para reemplazarlo con el nuevo. üîÑ

3. **Guardar en Memoria:** Almacenar la metadata y la tabla de resultados del experimento en la bit√°cora en memoria.

4. **Guardar en Disco (Opcional):** Si se solicita persistencia:
   - Guardar la metadata y los resultados en archivos Parquet separados.
   - Actualizar un archivo de "√≠ndice" central que sirve como un cat√°logo r√°pido de todos los experimentos guardados. üìá

// 18.3: Procesos de Consulta (`list_runs` y `get_run`)
// Se definen procesos para poder consultar la bit√°cora f√°cilmente.
- **Proceso "Listar Corridas":** Ofrece una vista de resumen de todos los experimentos registrados, ya sea leyendo desde la memoria o desde el √≠ndice en disco.
- **Proceso "Obtener Corrida":** Permite recuperar todos los detalles (metadata y tabla de resultados) de un experimento espec√≠fico usando su ID √∫nico.

FIN: Sistema de Registro Definido

//--- Parte 19: Diagn√≥stico Profundo e Interpretabilidad del Modelo Final ---

// 19.1: Definici√≥n del "Panel de Diagn√≥stico"
// Se define un conjunto de herramientas de an√°lisis avanzado para "interrogar" a cualquier modelo.
- **Curvas de Aprendizaje:** Para diagnosticar si el modelo tiene "hambre" de m√°s datos o si est√° sobreajustando.
- **An√°lisis SHAP:** Una "radiograf√≠a" del modelo para ver la contribuci√≥n exacta (positiva o negativa) de cada variable en cada predicci√≥n.  R√∂ntgen
- **Importancia por Permutaci√≥n:** Para identificar las variables m√°s cr√≠ticas, barajando sus valores y midiendo cu√°nto "empeora" el rendimiento.
- **Gr√°ficos de Dependencia Parcial (PDP):** Para visualizar la relaci√≥n que el modelo ha aprendido entre una variable y el resultado (ej. "a m√°s temperatura, m√°s...").
- **An√°lisis de Sensibilidad (¬±10%):** Una prueba pr√°ctica para medir qu√© tanto cambia la predicci√≥n si alteramos cada variable de entrada en un 10%.

// 19.2: Selecci√≥n del Modelo "Campe√≥n"
// Se define un proceso final de "campeonato" para elegir al mejor modelo absoluto.
1. REUNIR a todos los modelos finalistas de las optimizaciones anteriores (GridSearch y Optuna).
2. RE-ENTRENAR y EVALUAR a todos los candidatos en un mismo conjunto de datos de prueba para asegurar una comparaci√≥n justa.
3. DECLARAR como "campe√≥n" al modelo con el menor error (RMSE). üèÜ

// 19.3: Proceso de "Examen Final" del Modelo
// El modelo ganador es sometido a un examen exhaustivo.
INICIAR un bucle final que se ejecutar√° PARA CADA una de las variables objetivo.
  1. **Elegir al Campe√≥n:** Ejecutar el proceso de "campeonato" para el objetivo actual y anunciar al ganador y su rendimiento final.
  2. **Someter al Examen:** Aplicar el "Panel de Diagn√≥stico" completo al modelo campe√≥n:
      a. GENERAR y MOSTRAR sus Curvas de Aprendizaje.
      b. GENERAR y MOSTRAR los gr√°ficos de an√°lisis SHAP.
      c. IDENTIFICAR sus variables m√°s importantes y GENERAR los Gr√°ficos de Dependencia Parcial para ellas.
      d. REALIZAR y MOSTRAR el An√°lisis de Sensibilidad.

FIN: Diagn√≥stico y An√°lisis de Interpretabilidad Completado